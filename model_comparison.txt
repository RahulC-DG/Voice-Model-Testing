# Multi-Model Speech-to-Text Comparison Platform

## Project Overview
Expand the current Deepgram vs AssemblyAI demo to include multiple STT models with:
1. Deepgram Nova-3 (left panel) - fixed
2. Dropdown selection (right panel) for: AssemblyAI, Cartesia Ink-Whisper, ElevenLabs Scribe
3. Two main pages: STT Comparison + Voice Agent Configuration

## Current State Analysis
- ‚úÖ Deepgram Nova-3: Working with WebSocket streaming
- ‚úÖ AssemblyAI Universal Streaming v3: Already implemented and working
- ‚ùå Cartesia: Not yet integrated
- ‚ùå ElevenLabs: Not yet integrated

## Model Specifications

### 1. Deepgram Nova-3 (Current - Working)
- **Status**: ‚úÖ Fully functional
- **API**: WebSocket streaming
- **Endpoint**: wss://api.deepgram.com/v1/listen
- **Audio Format**: WebM/Opus (browser native)
- **Latency**: ~100-200ms
- **Pricing**: ~$0.0043/minute
- **SDK**: @deepgram/sdk v3.0.0

### 2. AssemblyAI Universal Streaming v3 (Current - Working)
- **Status**: ‚úÖ Already implemented and functional
- **API**: WebSocket streaming (Universal Streaming v3)
- **Endpoint**: wss://streaming.assemblyai.com/v3/ws
- **Audio Format**: PCM16 (currently configured)
- **Latency**: ~300ms
- **Pricing**: ~$0.15/hour
- **Implementation**: Direct WebSocket connection (no SDK)
- **Features**: Turn-based transcription, immutable results, intelligent endpointing

### 3. Cartesia Ink-Whisper (New Integration)
- **Status**: üÜï Ready to integrate
- **API**: WebSocket streaming
- **Endpoint**: wss://api.cartesia.ai/stt/websocket
- **Audio Format**: Multiple formats supported
- **Latency**: 66ms TTCT (fastest)
- **Pricing**: $0.13/hour (most affordable)
- **SDK**: @cartesia/cartesia-js or fetch API
- **Special Features**: Optimized for conversational AI, handles telephony artifacts

### 4. ElevenLabs Scribe v1 (Batch Only)
- **Status**: ‚ö†Ô∏è No streaming API yet
- **API**: REST API (batch processing only)
- **Endpoint**: https://api.elevenlabs.io/v1/speech-to-text
- **Audio Format**: Multiple formats supported
- **Latency**: N/A (batch processing)
- **Pricing**: $0.22-$0.48/hour
- **Accuracy**: Highest accuracy (98.7% Italian, 96.7% English)
- **Note**: Real-time streaming version "coming soon"

## Implementation Plan

### Phase 1: UI/UX Restructure
1. **Modify Layout**:
   - Keep Deepgram fixed on left panel
   - Add dropdown selector on right panel
   - Update color scheme for 4 models:
     - Deepgram: Red/Orange (#ff6b6b)
     - AssemblyAI: Cyan/Blue (#4ecdc4) 
     - Cartesia: Purple/Violet (#9b59b6)
     - ElevenLabs: Green/Emerald (#2ecc71)

2. **Add Model Selection Dropdown**:
   ```html
   <select id="comparison-model-select">
     <option value="assemblyai">AssemblyAI Universal v3</option>
     <option value="cartesia">Cartesia Ink-Whisper</option>
     <option value="elevenlabs">ElevenLabs Scribe (Batch Only)</option>
   </select>
   ```

3. **Update Stats Panel**:
   - Dynamic model names based on selection
   - Model-specific metrics (latency, pricing)
   - Connection status indicators

### Phase 2: Backend Integration

#### 2.1 Server.js Modifications
```javascript
// Add new dependencies
const { Cartesia } = require('@cartesia/cartesia-js');
const ElevenLabs = require('elevenlabs-node');

// Initialize clients
const cartesiaClient = new Cartesia({
  apiKey: process.env.CARTESIA_API_KEY,
});

const elevenLabsClient = new ElevenLabs({
  apiKey: process.env.ELEVENLABS_API_KEY,
});

// WebSocket handler modifications
wss.on('connection', (ws) => {
  let deepgramConnection = null;
  let comparisonConnection = null;
  let selectedModel = 'assemblyai'; // default
  
  ws.on('message', async (message) => {
    const data = JSON.parse(message);
    
    if (data.type === 'model-select') {
      selectedModel = data.model;
      // Initialize new comparison connection
      initializeComparisonModel(selectedModel);
    }
    
    if (data.type === 'audio-data') {
      // Send to Deepgram (always)
      if (deepgramConnection) {
        deepgramConnection.send(data.audio);
      }
      
      // Send to selected comparison model
      if (comparisonConnection) {
        sendToComparisonModel(selectedModel, data.audio);
      }
    }
  });
});
```

#### 2.2 Model-Specific Implementations

**AssemblyAI Universal Streaming v3 (Already Implemented)**:
```javascript
// Current implementation in server.js (lines 366-410)
const assemblyWsUrl = `wss://streaming.assemblyai.com/v3/ws?sample_rate=16000&encoding=pcm_s16le&format_turns=true`;

assemblyConnection = new WebSocket(assemblyWsUrl, {
  headers: {
    'Authorization': ASSEMBLYAI_API_KEY
  }
});

assemblyConnection.on('message', (message) => {
  const response = JSON.parse(message.toString());
  
  if (response.type === 'Turn') {
    if (response.transcript) {
      ws.send(JSON.stringify({
        type: 'assembly_transcript',
        data: { text: response.transcript }
      }));
    }
  }
});
```

**Cartesia Ink-Whisper**:
```javascript
async function initializeCartesia() {
  const socket = new WebSocket(
    `wss://api.cartesia.ai/stt/websocket?api_key=${process.env.CARTESIA_API_KEY}&cartesia_version=2025-04-16`
  );
  
  socket.onopen = () => {
    // Send configuration
    socket.send(JSON.stringify({
      model_id: 'ink-whisper',
      language: 'en',
      context_id: `session-${Date.now()}`,
      output_format: {
        container: 'raw',
        encoding: 'pcm_s16le',
        sample_rate: 16000
      }
    }));
  };
  
  socket.onmessage = (event) => {
    const data = JSON.parse(event.data);
    if (data.type === 'transcript') {
      ws.send(JSON.stringify({
        type: 'comparison-transcript',
        model: 'cartesia',
        transcript: data.text,
        is_final: data.is_final
      }));
    }
  };
  
  return socket;
}
```

**ElevenLabs Scribe (Batch Processing)**:
```javascript
async function processWithElevenLabs(audioBuffer) {
  try {
    const response = await fetch('https://api.elevenlabs.io/v1/speech-to-text', {
      method: 'POST',
      headers: {
        'xi-api-key': process.env.ELEVENLABS_API_KEY,
        'Content-Type': 'audio/mpeg'
      },
      body: audioBuffer
    });
    
    const result = await response.json();
    
    return {
      text: result.text,
      alignment: result.alignment,
      language: result.language_code
    };
  } catch (error) {
    console.error('ElevenLabs processing error:', error);
    return null;
  }
}
```

### Phase 3: Frontend Updates

#### 3.1 Client.js Modifications
```javascript
class MultiModelComparison {
  constructor() {
    this.deepgramConnection = null;
    this.comparisonModel = 'assemblyai';
    this.comparisonConnection = null;
    this.isRecording = false;
    this.audioChunks = []; // For ElevenLabs batch processing
  }
  
  initializeConnections() {
    // Deepgram connection (always active)
    this.initializeDeepgram();
    
    // Comparison model connection
    this.initializeComparisonModel();
  }
  
  switchComparisonModel(model) {
    this.comparisonModel = model;
    
    // Close existing comparison connection
    if (this.comparisonConnection) {
      this.comparisonConnection.close();
    }
    
    // Initialize new model
    this.initializeComparisonModel();
    
    // Update UI
    this.updateModelUI(model);
  }
  
  updateModelUI(model) {
    const panel = document.querySelector('.comparison-panel');
    const modelNames = {
      'assemblyai': 'AssemblyAI Universal v3',
      'cartesia': 'Cartesia Ink-Whisper',
      'elevenlabs': 'ElevenLabs Scribe'
    };
    
    panel.querySelector('h2').textContent = modelNames[model];
    panel.className = `transcript-panel comparison-panel ${model}-panel`;
  }
  
  handleAudioData(audioData) {
    // Send to Deepgram
    if (this.deepgramConnection && this.deepgramConnection.readyState === WebSocket.OPEN) {
      this.deepgramConnection.send(audioData);
    }
    
    // Handle comparison model
    if (this.comparisonModel === 'elevenlabs') {
      // Store for batch processing
      this.audioChunks.push(audioData);
    } else if (this.comparisonConnection && this.comparisonConnection.readyState === WebSocket.OPEN) {
      this.comparisonConnection.send(audioData);
    }
  }
  
  async stopRecording() {
    this.isRecording = false;
    
    // Process ElevenLabs batch if selected
    if (this.comparisonModel === 'elevenlabs' && this.audioChunks.length > 0) {
      await this.processElevenLabsBatch();
    }
    
    this.audioChunks = [];
  }
}
```

#### 3.2 CSS Updates
```css
/* Model-specific color schemes */
.deepgram-panel {
  border-left: 4px solid #ff6b6b;
  background: linear-gradient(135deg, #ff6b6b10 0%, #ff6b6b05 100%);
}

.assemblyai-panel {
  border-left: 4px solid #4ecdc4;
  background: linear-gradient(135deg, #4ecdc410 0%, #4ecdc405 100%);
}

.cartesia-panel {
  border-left: 4px solid #9b59b6;
  background: linear-gradient(135deg, #9b59b610 0%, #9b59b605 100%);
}

.elevenlabs-panel {
  border-left: 4px solid #2ecc71;
  background: linear-gradient(135deg, #2ecc7110 0%, #2ecc7105 100%);
}

/* Model selector dropdown */
.model-selector {
  margin: 20px 0;
  text-align: center;
}

.model-select {
  padding: 10px 15px;
  font-size: 16px;
  border: 2px solid #ddd;
  border-radius: 8px;
  background: white;
  min-width: 250px;
}

/* Batch processing indicator */
.batch-indicator {
  display: inline-block;
  padding: 4px 8px;
  background: #f39c12;
  color: white;
  border-radius: 4px;
  font-size: 12px;
  margin-left: 10px;
}
```

### Phase 4: Voice Agent Configuration Page

#### 4.1 New Route Structure
```
/                    - STT Comparison Demo
/voice-agent         - Voice Agent Configuration
```

#### 4.2 Voice Agent Page Features
```html
<!-- voice-agent.html -->
<div class="voice-agent-container">
  <div class="config-panel">
    <h2>Voice Agent Configuration</h2>
    
    <!-- STT Model Selection -->
    <div class="config-section">
      <h3>Speech-to-Text Model</h3>
      <select id="stt-model">
        <option value="deepgram">Deepgram Nova-3</option>
        <option value="assemblyai">AssemblyAI Universal v3</option>
        <option value="cartesia">Cartesia Ink-Whisper</option>
        <option value="elevenlabs">ElevenLabs Scribe</option>
      </select>
    </div>
    
    <!-- LLM Selection -->
    <div class="config-section">
      <h3>Language Model</h3>
      <select id="llm-model">
        <option value="gpt-4o">GPT-4o</option>
        <option value="claude-3.5">Claude 3.5 Sonnet</option>
        <option value="gemini-2.0">Gemini 2.0 Flash</option>
      </select>
    </div>
    
    <!-- TTS Selection -->
    <div class="config-section">
      <h3>Text-to-Speech Model</h3>
      <select id="tts-model">
        <option value="cartesia-sonic">Cartesia Sonic 2</option>
        <option value="elevenlabs">ElevenLabs</option>
        <option value="openai">OpenAI TTS</option>
      </select>
    </div>
    
    <!-- Voice Agent Persona -->
    <div class="config-section">
      <h3>Agent Persona</h3>
      <textarea id="system-prompt" placeholder="Define your voice agent's personality and role..."></textarea>
    </div>
    
    <button class="start-agent-btn">Start Voice Agent</button>
  </div>
  
  <div class="agent-interface">
    <!-- Live conversation interface -->
    <div class="conversation-display"></div>
    <div class="agent-controls">
      <button class="talk-btn">Hold to Talk</button>
      <button class="mute-btn">Mute Agent</button>
    </div>
  </div>
</div>
```

### Phase 5: Environment Variables
```bash
# .env file additions
CARTESIA_API_KEY=your_cartesia_key_here
ELEVENLABS_API_KEY=your_elevenlabs_key_here

# Existing
DEEPGRAM_API_KEY=your_deepgram_key_here
ASSEMBLYAI_API_KEY=your_assemblyai_key_here
```

### Phase 6: Package Dependencies
```json
{
  "dependencies": {
    "@cartesia/cartesia-js": "^1.0.0",
    "elevenlabs-node": "^1.0.0",
    "express": "^4.18.2",
    "ws": "^8.14.2",
    "@deepgram/sdk": "^3.0.0",
    "assemblyai": "^4.13.2",
    "dotenv": "^16.3.1",
    "multer": "^1.4.5-lts.1",
    "fluent-ffmpeg": "^2.1.2"
  }
}
```

## Implementation Priority

### Immediate (Week 1)
1. ‚úÖ Fix AssemblyAI Universal Streaming v3 integration
2. ‚úÖ Add Cartesia Ink-Whisper streaming integration
3. ‚úÖ Implement model selection dropdown UI

### Short-term (Week 2)
1. ‚úÖ Add ElevenLabs Scribe batch processing
2. ‚úÖ Implement voice agent configuration page
3. ‚úÖ Add comprehensive error handling

### Long-term (Week 3+)
1. ‚úÖ Advanced metrics and analytics
2. ‚úÖ Model performance benchmarking
3. ‚úÖ Export functionality for transcripts
4. ‚úÖ Real-time latency measurements

## Technical Considerations

### Audio Format Compatibility
- **Browser**: Produces WebM/Opus by default
- **Deepgram**: ‚úÖ Accepts WebM/Opus
- **AssemblyAI v3**: ‚úÖ Configured for PCM16 (Universal Streaming v3)
- **Cartesia**: ‚úÖ Accepts multiple formats including WebM
- **ElevenLabs**: ‚úÖ Accepts multiple formats (batch only)

### Latency Expectations
1. **Cartesia Ink-Whisper**: ~66ms (fastest)
2. **Deepgram Nova-3**: ~100-200ms
3. **AssemblyAI Universal v3**: ~300ms (already implemented)
4. **ElevenLabs Scribe**: N/A (batch processing)

### Cost Comparison (per hour)
1. **Cartesia**: $0.13 (most affordable)
2. **Deepgram**: ~$0.26
3. **ElevenLabs**: $0.22-$0.48
4. **AssemblyAI**: ~$0.15

### Error Handling Strategy
- Connection failures: Automatic retry with exponential backoff
- API rate limits: Queue management and throttling
- Audio format issues: Automatic format detection and conversion
- Model unavailability: Graceful fallback to alternative models

## Testing Strategy

### Unit Tests
- Individual model connection tests
- Audio format conversion tests
- WebSocket message handling tests

### Integration Tests
- End-to-end transcription accuracy tests
- Multi-model comparison tests
- Voice agent conversation flow tests

### Performance Tests
- Latency measurement across all models
- Concurrent connection handling
- Memory usage optimization

## Deployment Considerations

### Environment Setup
- Docker containerization for consistent deployment
- Environment variable management
- SSL certificate for WebSocket connections

### Monitoring
- Real-time connection status monitoring
- API usage tracking and alerting
- Performance metrics dashboard

### Scaling
- Load balancer configuration for WebSocket connections
- Database integration for conversation history
- CDN setup for static assets

## Future Enhancements

### Additional Models
- OpenAI Whisper (when streaming becomes available)
- Google Cloud Speech-to-Text
- Azure Cognitive Services Speech
- Amazon Transcribe (real-time)

### Advanced Features
- Custom vocabulary support
- Language detection and switching
- Speaker diarization comparison
- Sentiment analysis integration
- Real-time translation capabilities

### Analytics Dashboard
- Model accuracy comparison charts
- Cost analysis and optimization
- Usage patterns and insights
- A/B testing framework for model selection

This comprehensive plan provides a roadmap for expanding your STT comparison platform into a full-featured, multi-model voice AI demonstration and configuration tool.